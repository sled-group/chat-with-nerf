{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat_with_nerf.chat.agent import Agent \n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from chat_with_nerf.chat.session import Session\n",
    "import time\n",
    "import open3d as o3d\n",
    "from pathlib import Path\n",
    "from chat_with_nerf.chat.system_prompt import EDITED_SYSTEM_PROMPT, NO_VISUAL_FEEDBACK_SYSTEM_PROMPT\n",
    "from chat_with_nerf.settings import Settings\n",
    "from joblib import Parallel, delayed\n",
    "from evaluation_vis_util import draw_plotly, create_bbox\n",
    "from tqdm import tqdm\n",
    "import uuid\n",
    "from collections import OrderedDict\n",
    "from utils import is_label_unique, convert_origin_bbox, get_transformation_matrix, construct_bbox_corners, get_box3d_min_max, box3d_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_set(root_directory):\n",
    "    json_dict = {}\n",
    "    # List of all subfolders and their files\n",
    "    subfolders_files = [(dp, filenames) for dp, _, filenames in os.walk(root_directory)]\n",
    "    # Dictionary comprehension to pick only the first JSON from each subfolder\n",
    "    json_dict = {os.path.basename(dp): os.path.join(dp, filenames[0]) for dp, filenames in subfolders_files if any(fn.endswith('.json') for fn in filenames)}\n",
    "\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = ''  # Assuming current directory, adjust path if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT35\n",
    "# os.environ['API_URL'] = \"\"\n",
    "# os.environ['OPENAI_API_KEY'] = \"\"\n",
    "# GPT 4\n",
    "# os.environ['API_URL'] = \"\"\n",
    "# os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = get_val_set(root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_25 = 0\n",
    "acc_50 = 0\n",
    "acc_25_unique = 0\n",
    "acc_50_unique = 0\n",
    "acc_25_multiple = 0\n",
    "acc_50_multiple = 0\n",
    "list_iou = []\n",
    "total_object = 0\n",
    "total_unique_object = 0\n",
    "total_multiple_object = 0\n",
    "session_id_list = []\n",
    "acc_25_top2_hit = 0\n",
    "acc_25_top3_hit = 0\n",
    "acc_25_top5_hit =0\n",
    "acc_25_all_hit = 0\n",
    "acc_25_top2_hit_unique = 0\n",
    "acc_25_top2_hit_multiple = 0\n",
    "acc_25_top3_hit_unique = 0\n",
    "acc_25_top3_hit_multiple = 0\n",
    "acc_25_top5_hit_unique = 0\n",
    "acc_25_top5_hit_multiple = 0\n",
    "acc_25_all_hit_unique = 0\n",
    "acc_25_all_hit_multiple = 0\n",
    "\n",
    "\n",
    "result_dict ={\n",
    "    'scene_name': list(),\n",
    "    'description': list(),\n",
    "    'centroid_list': list(),\n",
    "    'extent_list': list(),\n",
    "    'similarity_mean_list_list': list(),\n",
    "    'ground truth': list()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_description(agent, scene_name, description, corners_original, is_unique, object_id, query_rank_id, center_original, extents_original):  \n",
    "    MAX_RETRIES = 3\n",
    "    for retry in range(MAX_RETRIES):\n",
    "        try:\n",
    "            new_session = Session.create_for_scene(scene_name)  \n",
    "            unique_id = str(uuid.uuid4())\n",
    "            new_session.session_id = f\"{scene_name}-{object_id}-{query_rank_id}-{unique_id}\" \n",
    "            new_session.working_scene_name = scene_name\n",
    "            new_session.grounding_query = description\n",
    "            new_session.ground_truth = [center_original, extents_original]\n",
    "            print(description)  \n",
    "            center_list, box_size_list, values_list = agent.act_no_gpt(  \n",
    "                description,  \n",
    "                scene_name,\n",
    "                new_session  \n",
    "            )  \n",
    "            combined_list = list(zip(values_list, center_list, box_size_list))\n",
    "            sorted_list = sorted(combined_list, key=lambda x: x[0], reverse=True)  # reverse=True for descending order\n",
    "            ordered_result = [(center, box_size) for _, center, box_size in sorted_list]\n",
    "\n",
    "            top1_hit_list = []\n",
    "            top2_hit_list = []\n",
    "            top3_hit_list = []\n",
    "            top5_hit_list = []\n",
    "            all_hit_list = []\n",
    "            \n",
    "            for index, (center, box_size) in enumerate(ordered_result):\n",
    "                cur_prediction = construct_bbox_corners(center, box_size)\n",
    "                iou3d_top = box3d_iou(np.array(corners_original), cur_prediction)\n",
    "                if index < 1:\n",
    "                    top1_hit_list.append(iou3d_top)\n",
    "                if index < 2:\n",
    "                    top2_hit_list.append(iou3d_top)\n",
    "                if index < 3:\n",
    "                    top3_hit_list.append(iou3d_top)\n",
    "                if index < 5:\n",
    "                    top5_hit_list.append(iou3d_top)\n",
    "                all_hit_list.append(iou3d_top)\n",
    "            \n",
    "            top1_hit = max(top1_hit_list)\n",
    "            top2_hit = max(top2_hit_list)\n",
    "            top3_hit = max(top3_hit_list)\n",
    "            top5_hit = max(top5_hit_list)\n",
    "            all_hit = max(all_hit_list)\n",
    "            \n",
    "            new_session.center_list = [arr.tolist() for arr in center_list]\n",
    "            new_session.box_size_list = [list(arr) for arr in box_size_list]\n",
    "            new_session.values_list = values_list\n",
    "            \n",
    "            new_session.save(\"/workspace/chat-with-nerf-dev/chat-with-nerf/session_output_lerf_14_with_baseline_final\")\n",
    "            return top1_hit, top2_hit, top3_hit, top5_hit, all_hit, new_session.session_id, new_session, is_unique\n",
    "        except Exception as exp:\n",
    "            if retry < MAX_RETRIES - 1:  # If it's not the last retry\n",
    "                print(f\"Attempt {retry + 1} failed. Retrying... Error is {exp}\")\n",
    "                continue\n",
    "            else:  # On the last retry, print the exception and return a message\n",
    "                print(exp)\n",
    "                # return f\"Failed after {MAX_RETRIES} attempts.\", None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scene(scene_name, json_path, json_dict):\n",
    "    scene_path = json_dict[scene_name]\n",
    "    with open(scene_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    furnitures = data['objects']\n",
    "    agent = Agent(scene_name=scene_name)\n",
    "    \n",
    "    results = []\n",
    "    total_unique_object = 0\n",
    "    total_multiple_object = 0\n",
    "    total_object = 0\n",
    "    preprocessed_data = []\n",
    "\n",
    "    for furniture in furnitures:\n",
    "        bbox = furniture['bbox']\n",
    "        center_original, extents_original = bbox[:3], bbox[3:6]\n",
    "        corners_original = construct_bbox_corners(center_original, extents_original)\n",
    "        label = furniture['label']\n",
    "        is_unique = is_label_unique(furnitures, label)\n",
    "        \n",
    "        if is_unique:\n",
    "            total_unique_object += len(furniture['description'])\n",
    "        else:\n",
    "            total_multiple_object += len(furniture['description'])\n",
    "        \n",
    "        for idx, description in enumerate(furniture['description']):\n",
    "            total_object += 1\n",
    "            preprocessed_data.append((agent, scene_name, description, corners_original, is_unique, label, idx, center_original, extents_original))\n",
    "\n",
    "    return total_unique_object, total_multiple_object, total_object, preprocessed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only include scenes that are within the first 7 entries\n",
    "selected_scenes = list(json_dict.items())[:7]\n",
    "\n",
    "results = Parallel(n_jobs=7)(delayed(process_scene)(scene_name, json_path, json_dict) for scene_name, json_path in selected_scenes)\n",
    "\n",
    "# Collate results\n",
    "total_unique_object = sum(result[0] for result in results)\n",
    "total_multiple_object = sum(result[1] for result in results)\n",
    "total_object = sum(result[2] for result in results)\n",
    "preprocessed_data = [item for result in results for item in result[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=5, backend='threading')(delayed(process_description)(*data) for data in tqdm(preprocessed_data, desc=\"Processing descriptions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_iou = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    top1_hit, top2_hit, top3_hit, top5_hit, all_hit, session_id, session, is_unique = result\n",
    "    \n",
    "    if top1_hit:\n",
    "        if top1_hit > 0.25:  \n",
    "            acc_25 += 1\n",
    "            if is_unique:  \n",
    "                acc_25_unique += 1  \n",
    "            else:\n",
    "                acc_25_multiple += 1  \n",
    "        if top1_hit > 0.5:\n",
    "            acc_50 += 1  \n",
    "            if is_unique:  \n",
    "                acc_50_unique += 1  \n",
    "            else:  \n",
    "                acc_50_multiple += 1\n",
    "    else:\n",
    "        top1_hit = 0\n",
    "        sessionid = 'none'\n",
    "    \n",
    "    if top2_hit:\n",
    "        if top2_hit > 0.25:\n",
    "            acc_25_top2_hit += 1\n",
    "            if is_unique:\n",
    "                acc_25_top2_hit_unique += 1\n",
    "            else:\n",
    "                acc_25_top2_hit_multiple += 1\n",
    "    \n",
    "    if top3_hit:\n",
    "        if top3_hit > 0.25:\n",
    "            acc_25_top3_hit += 1\n",
    "            if is_unique:\n",
    "                acc_25_top3_hit_unique += 1\n",
    "            else:\n",
    "                acc_25_top3_hit_multiple += 1\n",
    "    \n",
    "    if top5_hit:\n",
    "        if top5_hit > 0.25:\n",
    "            acc_25_top5_hit += 1\n",
    "            if is_unique:\n",
    "                acc_25_top5_hit_unique += 1\n",
    "            else:\n",
    "                acc_25_top5_hit_multiple += 1\n",
    "                \n",
    "    if all_hit:\n",
    "        if all_hit > 0.25:\n",
    "            acc_25_all_hit += 1\n",
    "            if is_unique:\n",
    "                acc_25_all_hit_unique += 1\n",
    "            else:\n",
    "                acc_25_all_hit_multiple += 1\n",
    "                \n",
    "                \n",
    "    list_iou.append(top1_hit)\n",
    "    session_id_list.append(session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"acc_25 =\", acc_25)\n",
    "print(\"acc_50 =\", acc_50)\n",
    "print(\"acc_25_unique =\", acc_25_unique)\n",
    "print(\"acc_50_unique =\", acc_50_unique)\n",
    "print(\"acc_25_multiple =\", acc_25_multiple)\n",
    "print(\"acc_50_multiple =\", acc_50_multiple)\n",
    "print(\"acc_25_top2_hit =\", acc_25_top2_hit)\n",
    "print(\"acc_25_top3_hit =\", acc_25_top3_hit)\n",
    "print(\"acc_25_top5_hit =\", acc_25_top5_hit)\n",
    "print(\"acc_25_all_hit =\", acc_25_all_hit)\n",
    "print('total_object: ', total_object)\n",
    "print('total_unique_object: ', total_unique_object)\n",
    "print('total_multiple_object: ', total_multiple_object)\n",
    "print(\"acc_25_top2_hit_unique: \", acc_25_top2_hit_unique)\n",
    "print(\"acc_25_top2_hit_multiple: \", acc_25_top2_hit_multiple)\n",
    "print(\"acc_25_top3_hit_unique: \", acc_25_top3_hit_unique)\n",
    "print(\"acc_25_top3_hit_multiple: \", acc_25_top3_hit_multiple)\n",
    "print(\"acc_25_top5_hit_unique: \", acc_25_top5_hit_unique)   \n",
    "print(\"acc_25_top5_hit_multiple: \", acc_25_top5_hit_multiple)\n",
    "print(\"acc_25_all_hit_unique: \", acc_25_all_hit_unique)\n",
    "print(\"acc_25_all_hit_multiple: \", acc_25_all_hit_multiple)\n",
    "print(\"list_iou =\", list_iou)\n",
    "print(\"total_object =\", total_object)\n",
    "print(\"session_id_list =\", session_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_hit, top2_hit, top3_hit, top5_hit, all_hit, session_id, session, is_unique = results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
