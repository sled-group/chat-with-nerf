{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import clip\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from evaluation_vis_util import draw_plotly, create_bbox\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from utils import find_clusters, ground_open_scene_embedding, get_transformation_matrix, is_label_unique, construct_bbox_corners, get_box3d_min_max, box3d_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = '/workspace/backup/chat-with-nerf-16/chat-with-nerf-eval/data/scanrefer_val2'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_set():\n",
    "    json_dict = {}\n",
    "    # List of all subfolders and their files\n",
    "    subfolders_files = [(dp, filenames) for dp, _, filenames in os.walk(root_directory)]\n",
    "    # Dictionary comprehension to pick only the first JSON from each subfolder\n",
    "    json_dict = {os.path.basename(dp): os.path.join(dp, filenames[0]) for dp, filenames in subfolders_files if any(fn.endswith('.json') for fn in filenames)}\n",
    "\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = get_val_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 0\n",
    "for scene_name, json_path in json_dict.items():\n",
    "    scene_path = json_dict[scene_name]\n",
    "    with open(scene_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    furnitures = data['objects']\n",
    "    for furniture in furnitures:\n",
    "        for idx, description in enumerate(furniture['description']):\n",
    "            number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_25 = 0\n",
    "acc_50 = 0\n",
    "acc_25_unique = 0\n",
    "acc_50_unique = 0\n",
    "acc_25_multiple = 0\n",
    "acc_50_multiple = 0\n",
    "list_iou = []\n",
    "total_object = 0\n",
    "total_unique_object = 0\n",
    "total_multiple_object = 0\n",
    "session_id_list = []\n",
    "is_unique_list = []\n",
    "\n",
    "result_dict ={\n",
    "    'scene_name': list(),\n",
    "    'description': list(),\n",
    "    'centroid_list': list(),\n",
    "    'extent_list': list(),\n",
    "    'similarity_mean_list_list': list(),\n",
    "    'ground truth': list()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scene_name, json_path in json_dict.items():\n",
    "    scene_path = json_dict[scene_name]\n",
    "    with open(scene_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    furnitures = data['objects']\n",
    "    alignment_matrix = Path(\"/workspace/backup/chat-with-nerf-16/chat-with-nerf-eval/data/scannet/scans\")\n",
    "    specific_file_path = alignment_matrix / scene_name / (scene_name + \".txt\")\n",
    "    axisAlignment_matrix = get_transformation_matrix(specific_file_path)\n",
    "    \n",
    "    mesh = o3d.io.read_triangle_mesh(f\"/workspace/backup/chat-with-nerf-16/chat-with-nerf-eval/data/scannet/scans/{scene_name}/{scene_name}_vh_clean_2.ply\")  # replace with your file path and format\n",
    "    if not mesh.has_vertex_normals(): mesh.compute_vertex_normals()\n",
    "    if not mesh.has_triangle_normals(): mesh.compute_triangle_normals()\n",
    "    # aligned_vertices = np.load(\"/workspace/openscene_data/scene0025_00/scene0025_00_aligned_vert.npy\")\n",
    "    mesh_vertices = np.asarray(mesh.vertices)\n",
    "    axis_align_matrix = np.array(axisAlignment_matrix).reshape((4,4))\n",
    "    pts = np.ones((mesh_vertices.shape[0], 4))\n",
    "    pts[:,0:3] = mesh_vertices[:,0:3]\n",
    "    pts = np.dot(pts, axis_align_matrix.transpose()) # Nx4\n",
    "    aligned_vertices = np.copy(mesh_vertices)\n",
    "    aligned_vertices[:,0:3] = pts[:,0:3]\n",
    "    mesh.vertices = o3d.utility.Vector3dVector(aligned_vertices)\n",
    "    clip_embedding = np.load(f'/workspace/backup/chat-with-nerf-16/chat-with-nerf-data/openscene_data/{scene_name}/{scene_name}_vh_clean_2_openscene_feat_distill.npy')\n",
    "    print(f\"Processing {scene_name}\")\n",
    "    for furniture in furnitures:\n",
    "        bbox = furniture['bbox']\n",
    "        center_original, extents_original = bbox[:3], bbox[3:6]\n",
    "        corners_original = construct_bbox_corners(center_original, extents_original)\n",
    "        label = furniture['label']\n",
    "        is_unique = is_label_unique(furnitures, label)\n",
    "        descriptions = furniture['description']\n",
    "        print(f\"Processing descriptions: {descriptions}\")\n",
    "        if is_unique:\n",
    "            total_unique_object += len(descriptions)\n",
    "        else:\n",
    "            total_multiple_object += len(descriptions)\n",
    "        for description in descriptions:\n",
    "            is_unique_list.append(is_unique)\n",
    "            total_object += 1\n",
    "            centroids, extents, similarity_mean_list = ground_open_scene_embedding(description, device, model, clip_embedding, mesh)\n",
    "            result_dict['scene_name'].append(scene_name)\n",
    "            result_dict['description'].append(description)\n",
    "            result_dict['centroid_list'].append(centroids)\n",
    "            result_dict['extent_list'].append(extents)\n",
    "            result_dict['similarity_mean_list_list'].append(similarity_mean_list)\n",
    "            result_dict['ground truth'].append(center_original + extents_original)\n",
    "            iou3d_list = []\n",
    "            for center, extend in zip(centroids, extents):\n",
    "                prediction = construct_bbox_corners(center, extend)\n",
    "                iou3d = box3d_iou(np.array(corners_original), prediction)\n",
    "                iou3d_list.append(iou3d)\n",
    "            \n",
    "            max_iou = max(iou3d_list)\n",
    "            if max_iou > 0.25:\n",
    "                acc_25 += 1\n",
    "                if is_unique:\n",
    "                    acc_25_unique += 1\n",
    "                else:\n",
    "                    acc_25_multiple += 1\n",
    "            if max_iou > 0.5:\n",
    "                acc_50 += 1\n",
    "                if is_unique:\n",
    "                    acc_50_unique += 1\n",
    "                else:\n",
    "                    acc_50_multiple += 1\n",
    "            list_iou.append(max_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"acc_25 =\", acc_25)\n",
    "print(\"acc_50 =\", acc_50)\n",
    "print(\"acc_25_unique =\", acc_25_unique)\n",
    "print(\"acc_50_unique =\", acc_50_unique)\n",
    "print(\"acc_25_multiple =\", acc_25_multiple)\n",
    "print(\"acc_50_multiple =\", acc_50_multiple)\n",
    "print(\"list_iou =\", list_iou)\n",
    "print(\"total_object =\", total_object)\n",
    "print(\"total_unique_object =\", total_unique_object)\n",
    "print(\"total_multiple_object =\", total_multiple_object)\n",
    "print(\"session_id_list =\", session_id_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
